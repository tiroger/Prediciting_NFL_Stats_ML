{% extends "layout.html" %} {% block content %}
<div class="container" id="model-build">
  <h2>Building the Model</h2>
  <div id="container">
    <img
      src="https://pngimage.net/wp-content/uploads/2018/06/machine-learning-png.png"
      alt="machine brain"
      style="float: right; width:288px;height:262px;"
    />
    <p>
      The data set used for our model contains a detailed play-by-play account
      of every single play ran over the course of 10 season. It contains,
      geographical and date information, the type of play that was called, the
      number of yeards gained from said play, down, clock and field positioning,
      among others. It also contains offensive stats on each player directly
      involved in the play, such as passing and rushing yards, yards ran after a
      catch, etc, and defensive stats, such as fumbles and interceptions, and of
      course play outcome, e.g. touchdown, field goal, etc.
    </p>
  </div>

  <p>
    In order to create a model that can predict which play is the likeliest to
    be called, we reasoned that any information relating to the state prior to
    calling the play would be critical in informing the decision to run a pass
    or a run play, or alternatively to kick a field goal or punt. We limited our
    predictions to one these for several reasons:
  </p>

  <ol>
    <li class="features" style="padding-bottom: 16px;">
      Kickoffs were removed as they only occur at the beginning of the game/half
      or after a scoring drive. Decisions don't factor in other then the type of
      kick, e.g. long, short or onside kick.
    </li>
    <li class="features" style="padding-bottom: 16px;">
      Edge cases, such as QB kneel or spiking where also dropped as occur under specific circumstances.
    </li>
    <!-- <li class="features" style="padding-bottom: 16px;">
      Punts and field goals occur almost exclusively on 4th down and the decision to run
      either play is largely determined by field positioning.
    </li> -->
  </ol>

  <div class="row">
  <div class="col-sm-6">
    <h5>Play Breakdown - All Plays</h5>
    <div>
    <iframe width="500px" height="500px" frameborder="0" scrolling="no" src="//plot.ly/~rogerlefort/4.embed?showlink=false"></iframe>
</div>
  </div>
  <div class="col-sm-6">
    <h5>Play Breakdown - Pass, Run, FG, Punt</h5>
    <div>
    <iframe width="500px" height="500px" frameborder="0" scrolling="no" src="//plot.ly/~rogerlefort/113.embed?showlink=false"></iframe>
</div>

  </div>
  </div>
<br>
  <h3>Feature Selection</h3>
  <p>
    The original dataset contains 254! features. After cleaning the data and supplementing with weather information, we focused on features, which would be predicted to influence play calling.
  </p>
  <h4>Intrinsic Features</h4>
  <p>
    The goal of a play is to gain as many yards as possible, 10 at a minimum,
    generally over the course of 3 downs, as a team marches down the field towards scoring a touchdown or a fieldgoal. As such we would expect "down" and
    "distance-to-go" to be critical in deciding which play to call. Passes
    net more yards on average, but short distances are typically easier to obtain
    running the ball. Time remaining in the half or in the game and score differential are
    also a crucial considerations. Finally, we reasoned that field positioning
    could be important, but largely dependent on other factors, such as time
    remaining and the number of time outs a team possesses, which we also
    included as our inital set of feature:
  </p>
  <ul>
    <li class="features" style="padding-bottom: 16px;">Yard line (yardline_100)</li>
    <li class="features" style="padding-bottom: 16px;">Quarter (qtr)</li>
    <li class="features" style="padding-bottom: 16px;">Time remaining in the half (half_seconds_remaining)</li>
    <li class="features" style="padding-bottom: 16px;">Time remaining in the game (game_seconds_remaining)</li>
    <li class="features" style="padding-bottom: 16px;"> Current down (down)</li>
    <li class="features" style="padding-bottom: 16px;">Yards-to-go to 1st down or TD (ydstogo)</li>
    <li class="features" style="padding-bottom: 16px;">Timeouts remaing, possession team (posteam_timeouts_remaining)</li>
    <li class="features" style="padding-bottom: 16px;">Timeouts remaing, defending team (defteam_timeouts_remaining)</li>
    <li class="features" style="padding-bottom: 16px;">Score differential (score_differential)</li>
  </ul>

  <h4>Extrinsic Features</h4>
  <p>
    As discussed earlier, weather plays a critical part in deciding which play to call. For example, under heavy rains or strong winds, loss of grip and visibility may favor running plays. We sought out to detemine whether weather conditions could improve our learning model. The following game time weather parameters were included:
  </p>
  <ul>
    <li class="features" style="padding-bottom: 16px;">Temperature</li>
    <li class="features" style="padding-bottom: 16px;">Precipitation (amount)</li>
    <li class="features" style="padding-bottom: 16px;">Snow (amount)</li>
    <li class="features" style="padding-bottom: 16px;">Wind speeds</li>
    <li class="features" style="padding-bottom: 16px;">Visibility</li>
    <li class="features" style="padding-bottom: 16px;">Humidity</li>
  </ul>

  <p>
    To facilitate the exploratory data analysis phase, we used the extremely useful library, <a class= 'hyperlink' href='https://github.com/pandas-profiling/pandas-profiling'>pandas_profiling</a>. For each feature in our dataset, the following statistics - if relevant for the column type - were obtained --available in an interactive <a class='hyperlink' href='/feature-profile'>HTML report</a>:</p>
<ul>
  <li class="features" style="padding-bottom: 16px;"><b>Essentials</b>: type, unique values, missing values</li>
  <li class="features" style="padding-bottom: 16px;"><b>Quantile statistics</b> like minimum value, Q1, median, Q3, maximum, range, interquartile range</li>
  <li class="features" style="padding-bottom: 16px;"><b>Descriptive statistics</b> like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness</li>
  <li class="features" style="padding-bottom: 16px;"><b>Most frequent values</b></li>
  <li class="features" style="padding-bottom: 16px;"><b>Histogram</b></li>
  <li class="features" style="padding-bottom: 16px;"><b>Correlations</b> highlighting of highly correlated variables, Spearman and Pearson matrixes</li>
</ul>
<p>None of the features we intuitively selected showed any significant correlation. However, a number of features include several outliers, especially the score differential. We can verify that these extreme values are from actual games, and not entry errors. For example, the largest score differential (59 points) was from an <a href='https://www.espn.com/nfl/game?gameId=291018017' class='subtle-hyperlink'>October 19th, 2009 game</a> between the New Englan Patriots and the Tennessee Titans, which ended with a score of 59-0 in favor of the Patriots. Interestingly, the largest distance-to-go value (50) occured on a 3rd and 50 situation, in a game between the Washington Redskins and the Cincinnati Bengals on <a href='https://www.espn.com/nfl/playbyplay?gameId=320923028' class='subtle-hyperlink'>September 23rd, 2012.</a></p>
<div>
  <div class="row">
  <div class="col-sm-6">
    <h5>Correlation Matrix</h5>
    <div>
      <img src='/static/images/correlation_matrix.png' alt="correlation matrix" style="width:500px;height:500px;"/>
    </div>
  </div>
  <div class="col-sm-6">
    <h5>Feature Box Plot</h5>
    <div>
    <img src='/static/images/box_plot_only_outliers.png' alt="box plot" style="width:500px;height:500px;"/>
    </div>
  </div>
  </div>
</div>
  <div class="line"></div>

  <h3>Models</h3>
  <div class="row">
  <div class="col-sm-5">
    <!-- <h5>Before</h5> -->
    <div>
      <p>
        Since there are four possible play outcomes, this boils down to a multi-class classification problem. Given a set of pre-existing game and weather conditions, what is the predicted play call. After cleaning and aggregating the data, we ran multiple algorithms, encompassing regression, ensemble and boosting models:
      </p>
      <ul>
        <li class="features" style="padding-bottom: 16px;">Logistic Regression</li>
        <li class="features" style="padding-bottom: 16px;">Logistic Regression w/ Cross Validation</li>
        <li class="features" style="padding-bottom: 16px;">Stochastic Gradient Descent (SDG)</li>
        <li class="features" style="padding-bottom: 16px;">K-Nearest Neighbor</li>
        <li class="features" style="padding-bottom: 16px;">Bagging meta-estimator</li>
        <li class="features" style="padding-bottom: 16px;">AdaBoost</li>
        <li class="features" style="padding-bottom: 16px;">XGBoost</li>
        <li class="features" style="padding-bottom: 16px;">Decision Tree</li>
        <li class="features" style="padding-bottom: 16px;">Extra Tree</li>
        <li class="features" style="padding-bottom: 16px;">Random Forest</li>
      </ul>
    </div>
  </div>
  <div class="col-sm-7">
    <h5>Accuracy Scores</h5>
    <!-- <h5>After</h5> -->
    <!-- <div> -->
    <iframe width="700" height="600" frameborder="0" scrolling="no" src="//plot.ly/~rogerlefort/108.embed?showlink=false"></iframe>
    <!-- <iframe width="600" height="600" frameborder="0" scrolling="no" src="//plot.ly/~rogerlefort/93.embed?showlink=false"></iframe> -->
    <!-- </div> -->
  </div>
  </div>
  <br>
  <div>
    <p>
      We found that the Random Forest classifer gave the best accuracy score (71.0%), followed closely by the Extra Tree classifier (70.3%). However, because of the imbalanced nature of our classes, accuracy score is not necessarily useful to evaluate the overall performance of the model (i.e. How well does the model recognize each class?). To get a better understanding of the model's performance, we also plotted the confusion matrix, which tells how well the models does for each class. The confusion matrix also gives us three important metrics, precision, recall and f1 score:</p>
      <div class="row">
      <div class="col-sm-7">
      <div>
      <ul>
         <li class="features" style="padding-bottom: 16px;"><b>Precision:</b> What proportion of <u>predicted</u> positives is truly positive? For example, the precision for the class "pass" is the number of correctly predicted pass plays out of all predicted pass plays.</li>
         <li class="features" style="padding-bottom: 16px;"><b>Recall:</b> What proportion of actual positives is correctly classified? For example, of the plays that are actually runs, how many were correctly classified as runs?</li>
         <li class="features" style="padding-bottom: 16px;"><b>f1 score:</b> The harmonic mean of the precision and recall,</li>
       </ul>
    </div>
  </div>
    <div class="col-sm-5">
      <img src="/static/images/precision_recall.png" id='matrix' style="width:420px;height:322px;"/>
    </div>
  </div>

  <script>
 window.onload = function() {
     document.getElementById("itemImage").onchange = showFormatImage;
  };
 function showFormatImage() {
    var image = document.getElementById("changeImage");
    image.src = $('select[name=itemImage] option:selected').attr('data-img');
    return false;
 }
  </script>

  <!-- <img src="/static/images/forrest_cm_all_plays_percent.svg" id='changeImage'style="width:600px;height:600px;"/> -->

  <div>
    <div class="row">
    <div class="col-sm-6">
      <div class='image-container'>
      <select id="itemImage" name="itemImage">
        <option data-img="/static/images/forrest_cm_all_plays_percent.png">Confusion Matrix</option>
        <option data-img="/static/images/forrest_pred_error_all_plays.png">Prediction Error</option>
        <option data-img="/static/images/forrest_all_plays.png">Classification Report</option>
        <!-- <option data-img="/static/images/forrest_ROCAUC_all_plays.png">AUCROC</option> -->
      </select>
    </div>
      <div>
        <img src="/static/images/forrest_cm_all_plays_percent.png" id='changeImage' style="width:500px;height:371px;"/>
      </div>
    </div>
    <div class="col-sm-6">
      <div>
        <br>
        <br>
      <p>
        From the confusion matrix, we can see that the model performs extremely well in distinguishing the proper instances of punts and field goals.
      </p>
      </div>
    </div>
    </div>
  </div>
  <div class="line"></div>


  <!-- <div class="dropdown"></div>
  <div id="dropdown-viz"></div> -->

<div class="line"></div>


<div class="line"></div>




  <div id="container">



    <!-- <script>
    var modelScores = ["Train Score", "Test Score"];
    var url = "/scores";
    var promise = d3.json(url);

    // Getting data from table route
    promise.then(function(data){
      // console.log(data);

    	// create the drop down menu of cities
    	var selector = d3.select("body")
    		.append("select")
    		.attr("id", "model")
    		.selectAll("option")
    		.data(data)
    		.enter().append("option")
    		.text(function(d) { return d.model; })
    		.attr("value", function (d, i) {
    			return i;
          console.log(d.model)
    		});
        // generate a random index value and set the selector to the city
      // at that index value in the data array
      var index = Math.round(Math.random() * data.length);
      d3.select("#model").property("selectedIndex", index);

      // append a paragraph tag to the body that shows the city name and it's population
      d3.select("body")
            .append("p")
            .data(data)
            .text(function(d){
              return data[index]['train_score'];
            })

      });
    </script> -->
    <script src="https://d3js.org/d3.v5.min.js"></script>
  </div>

  <div class="line"></div>



</div>

<!-- My Scripts -->
<script src="{{ url_for('static', filename='js/barChart.js') }}"></script>
<!-- D3 I HATE YOU! -->
<script src="https://d3js.org/d3.v3.min.js" charset="utf-8"></script>
{% endblock %}
